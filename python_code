#!/usr/bin/env python
# coding: utf-8

# In[34]:

import logging
import os
import re
import codecs
from multiprocessing import Pool, Queue
from pdfminer.pdfparser import PDFParser, PDFDocument
from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter
from pdfminer.converter import PDFPageAggregator
from pdfminer.layout import LAParams, LTTextBox, LTTextLine

directory = os.fsencode('Pdf_Testdata')

#turn off pdf miner logging
logging.propagate = False 
logging.getLogger().setLevel(logging.ERROR)


#declare lists to append to
emails_global = []
names = []
skipped_list = []

email_regex = re.compile(
    "^[a-zA-Z0-9.!#$%&'*+/=?^_`{|}~-]+@[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)*$"
    #"(?:[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*|\"(?:[\x01-\x08\x0b\x0c\x0e-\x1f\x21\x23-\x5b\x5d-\x7f]|\\[\x01-\x09\x0b\x0c\x0e-\x7f])*\")@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?|\[(?:(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9]))\.){3}(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9])|[a-z0-9-]*[a-z0-9]:(?:[\x01-\x08\x0b\x0c\x0e-\x1f\x21-\x5a\x53-\x7f]|\\[\x01-\x09\x0b\x0c\x0e-\x7f])+)\])"
    #"[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*@(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?"
    #"\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,4}\b"
)


queue = Queue()


# In[ ]:


#iterate directory, scan pdfs and turn into text, split and scan text for emails and append into output lists
#this loop has a very high runtime
#paths are relative


#for file in os.listdir(directory)[1:5] --> von 1-5
def getAllFiles(queue):
   for filename in os.listdir(directory):
       queue.put(filename)


def read_all_files(datei):
    emails_global = []
    names = []
    filename = os.fsdecode(datei)
    path = 'Pdf_Testdata\\' + filename
    try:
        fp = open(path, 'rb')    
        parser = PDFParser(fp)
        doc = PDFDocument()
        parser.set_document(doc)
        doc.set_parser(parser)
        doc.initialize('')
        rsrcmgr = PDFResourceManager()
        laparams = LAParams()
        laparams.char_margin = 1.0
        laparams.word_margin = 1.0
        device = PDFPageAggregator(rsrcmgr, laparams=laparams)
        interpreter = PDFPageInterpreter(rsrcmgr, device)
        extracted_text = ''
        email = None
        email2 = None

        for page in doc.get_pages():
            interpreter.process_page(page)
            layout = device.get_result()
            for lt_obj in layout:
                if isinstance(lt_obj, LTTextBox) or isinstance(lt_obj, LTTextLine):
                    extracted_text += lt_obj.get_text()
        
        emails_local = []
        
        removeSpecialChars = extracted_text.translate ({ord(c): " " for c in "Â©!#$%^&*()[]{};:,/<>?\|`~=+"})
        #print(removeSpecialChars)
        #removeSpecialChars = re.sub('\.$', '', removeSpecialChars)
        for word in removeSpecialChars.split():
            word = re.sub('\.$', '', word)
            if '@' in word:


                email = re.match(email_regex, word)
                #email2 = re.match(email_regex2,word)
                if email is not None:
                    emails_local.append(word)

                else:
                    emails_local.append('Keine Emails')
                    
        emails_global.append(emails_local)
        names.append(filename)
        #print(filename)
        
    except:
        print(filename + ' skipped due to error.')
        skipped_list.append(filename)
    
    with open("emails.txt","a") as f:
        for (name,email) in zip(names,emails_global):
            try:
                f.write(u"{0};{1}\n".format(name,email))
            except:
                print(name + 'skipped due to error')
                pass
    f.close()


# In[ ]:


#for file_i in os.listdir(directory):

#print(os.listdir(directory))
if __name__ == '__main__':
    dateien = os.listdir(directory)
    getAllFiles(queue)
    p = Pool()
    results = p.map(read_all_files, dateien)
    #pool = Pool(None, read_all_files, [queue])
    #p.apply_async(read_all_files, os.listdir(directory))

    p.close()
    #pool.join()


# In[23]:

names_temp = names

len(names)

temp_names = names

len(temp_names)

len(skipped_list)

temp_emails_global = emails_global

len(emails_global)

names

names_temp



